{
  "model": "llama3.2:1b",
  "messages": [
    {"role": "user", "content": "What is 2+2? Answer in one short sentence."}
  ],
  "max_tokens": 30
}
