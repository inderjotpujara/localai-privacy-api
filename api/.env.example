# LocalAI Configuration
LLM_BASE_URL=http://localai:8080/v1

# API Configuration  
PORT=3000

# For development, you might want to use:
# LLM_BASE_URL=http://localhost:8080/v1
